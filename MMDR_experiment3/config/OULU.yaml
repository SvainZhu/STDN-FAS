### The config of the MMDR network training and testing

# cuda options
GPU_USAGE: 0

# logger options
image_save_iter: 300         # How often do you want to save output images during training
image_display_iter: 10000       # How often do you want to display output images during training
display_size: 1               # How many images do you want to display each time
log_iter: 300                   # How often do you want to log the training stats

# optimization options
max_epochs: 30             # maximum number of training epochs
max_iters: 30000              # maximum number of training iterations
batch_size: 1                 # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: gaussian                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.001                    # initial learning rate
lr_policy: step               # learning rate scheduler
step_size: 3               # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate
reg_loss_r_w: 10            # weight of regularizer loss with liveness style feature
reg_loss_s_w: 0.01            # weight of regularizer loss with spoof style feature
reg_w: 6                      # weight of regularizer loss
gan_w: 2                      # weight of adversarial loss
est_w: 6                     # weight of style estimator loss
est_recon_w: 2                 # weight of style reconstruction estimator loss
pixel_recon_w: 2                  # weight of image reconstruction loss

# model options
gen:
  feature_c: 32               # number of the channels about content or style feature
  n_downsample: 3             # number of downsampling layers in content
  n_block: 1                  # number of blocks in encoder
  norm: bn                  # normalization layer [none/bn/in/ln]
  act: prelu                 # activation function [relu/lrelu/prelu/selu/tanh]
  pad_type: zero           # padding type [zero/reflect]
dis:
  input_c: 3                      # number of input channels
  output_c: 1                     # number of output channels
  num_scales: 3               # number of scales
  n_layer: 3                  # number of layers in D
  norm: bn                  # normalization layer [none/bn/in/ln]
  act: prelu                # activation function [relu/lrelu/prelu/selu/tanh]
  pad_type: zero           # padding type [zero/reflect]
est:
  input_c: 32                      # number of input channels
  output_c: 1                     # number of output channels
  n_layer: 3                  # number of layers in E
  norm: bn                  # normalization layer [none/bn/in/ln]
  act: prelu                # activation function [relu/lrelu/prelu/selu/tanh]
  pad_type: reflect           # padding type [zero/reflect]

# data options
input_channel: 3                              # number of image channels [1/3]
num_workers: 0                              # number of data loading threads
input_size: 256                               # the size of input image
data_csv_train: /media/l228/数据/zsw/Data/OULU/CSV_MMDR/1.6/train_1_6.csv      # a train dataset csv location
data_csv_test: /media/l228/数据/zsw/Data/OULU/CSV_MMDR/1.6/test_1_6.csv     # a test dataset csv location